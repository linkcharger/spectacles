{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, WebDriverException\n",
    "from time import sleep\n",
    "from os.path import exists\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from retrying import retry\n",
    "\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "\n",
    "def wait(min, max):\n",
    "    '''wait between min and max seconds'''\n",
    "    sleep(min + (max-min) * random())\n",
    "\n",
    "def reinitialise():   \n",
    "    '''close the selenium client, restart (ie wipe session cookies) and re-login'''\n",
    "    global bro\n",
    "    try: bro.close()\n",
    "    except: pass\n",
    "\n",
    "    bro = webdriver.Chrome('chromedriver.exe')\n",
    "    # bro.set_window_position(-1220, 70, windowHandle='current')\n",
    "    bro.maximize_window()\n",
    "    bro.implicitly_wait(3)\n",
    "\n",
    "    homepage = 'https://www.newspapers.com/'\n",
    "    bro.get(homepage)\n",
    "\n",
    "    # sleep(2)\n",
    "\n",
    "    try:\n",
    "        # click on 'accept all' cookies\n",
    "        bro.switch_to.frame('sp_message_iframe_604967')\n",
    "        bro.find_element_by_xpath('//button[@title=\"Accept All\"]').click()\n",
    "        bro.switch_to.parent_frame()\n",
    "    except: pass\n",
    "\n",
    "    # sign in \n",
    "    bro.find_element_by_xpath('//*[@id=\"signinlink\"]').click()  # sign in button\n",
    "    # sleep(2)\n",
    "\n",
    "    loginFields = bro.find_element_by_id('username')\n",
    "    loginFields.clear()\n",
    "    loginFields.send_keys('elliott.t.ash@gmail.com')\n",
    "    loginFields.send_keys('\\tnews0952') # didnt accept any identifier or xpath -> do it manually\n",
    "\n",
    "    signinButton = bro.find_element_by_xpath('//*[@id=\"SignInModal\"]/div/div[2]/div/div[3]/div/button')\n",
    "    signinButton.click()\n",
    "    sleep(5)\n",
    "\n",
    "    return bro\n",
    "\n",
    "def retryOnTheseExceptions(exceptionToTest):\n",
    "    return isinstance(exceptionToTest, WebDriverException) or isinstance(exceptionToTest, ElementClickInterceptedException)\n",
    "\n",
    "def backup(dic, path):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(obj=dic, fp=f, indent=4)\n",
    "\n",
    "def restore(path):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def unravelCoverage(coverage):\n",
    "    rows = [] \n",
    "\n",
    "    for state in coverage.keys():\n",
    "        for city in coverage[state].keys():\n",
    "            for newspaper in coverage[state][city].keys():\n",
    "\n",
    "                dates = [f'{year}-{month:02}' for year in range(1690, 2020) for month in range(1, 13)]\n",
    "\n",
    "                s = pd.Series(index=['state', 'city', 'newspaper', 'location']+dates, dtype='float')\n",
    "                s['state'] = state           \n",
    "                s['city'] = city           \n",
    "                s['newspaper'] = newspaper           \n",
    "                s['location'] = coverage[state][city][newspaper]['location']\n",
    "                \n",
    "                for date, value in coverage[state][city][newspaper]['data'].items():\n",
    "                    s[date] = value\n",
    "\n",
    "                rows.append(pd.DataFrame(s).T)\n",
    "\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    df.to_excel('coverage_over_time.xlsx')\n",
    "\n",
    "def unravelSpectacleMentions(spectacleMentions):\n",
    "    rows = [] \n",
    "\n",
    "    for state in spectacleMentions.keys():\n",
    "        for city in spectacleMentions[state].keys():\n",
    "            for newspaper in spectacleMentions[state][city].keys():\n",
    "\n",
    "                dates = [f'{year}-{month:02}' for year in range(1690, 2020) for month in range(1, 13)]\n",
    "\n",
    "                s = pd.Series(index=['state', 'city', 'newspaper']+dates, dtype='float')\n",
    "                s['state'] = state           \n",
    "                s['city'] = city           \n",
    "                s['newspaper'] = newspaper           \n",
    "                \n",
    "                for date, value in spectacleMentions[state][city][newspaper].items():\n",
    "                    s[date] = value\n",
    "\n",
    "                rows.append(pd.DataFrame(s).T)\n",
    "\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    df.to_excel('spectacleMentions_over_time.xlsx')\n",
    "\n",
    "def resetView():\n",
    "    '''click on left arrow to reset view (so that column numbers dont get shifted)'''\n",
    "    global bro\n",
    "\n",
    "    try: \n",
    "        bro.find_element_by_xpath('//*[@id=\"bc_previous\"]').click()    \n",
    "        bro.find_element_by_xpath('//*[@id=\"bc_previous\"]').click()    \n",
    "    except: \n",
    "        pass \n",
    "    \n",
    "\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "##########################################################################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait 2^x seconds between each retry, up to 1h, then 1h forever afterwards\n",
    "@retry(wait_exponential_multiplier=1_000, wait_exponential_max=60*60*1_000, retry_on_exception=retryOnTheseExceptions)\n",
    "# wait between 20 and 40min to restart\n",
    "# @retry(wait_random_min=20*60*1000, wait_random_max=40*60*1000)\n",
    "def scrape():\n",
    "    '''scrape the 'browsing' section of newspapers.com. \n",
    "    get \n",
    "        - number of monthly publications of all newspapers by state, city and newspaper; \n",
    "        - number of hits for 'spectacles OR glasses' in that month, and \n",
    "        - location of newspaper\n",
    "\n",
    "    flow: \n",
    "        1) read existing data from files if exists (dict is saved after each successful city) \n",
    "\n",
    "        2) reinitialise browser (clears cookies and everything)\n",
    "\n",
    "        3) go loopy into states, cities, newspapers - retrieving data if it exists, creating empty dict if does not (to allow further steps)\n",
    "\n",
    "        4) at newspaper level, \n",
    "            if newspaper data already exists:\n",
    "                skip to next newspaper\n",
    "                (and thus eventually to next city, next state, if those are complete)\n",
    "            if data does not exist:\n",
    "                get number of publications in a month\n",
    "                get number of hits for 'spectacles OR glasses'\n",
    "                once all years and months are collected: \n",
    "                    get location of newspaper\n",
    "                    backup whole dicts to files\n",
    "\n",
    "    once complete, unravel dicts into DFs and save to file.\n",
    "    '''\n",
    "\n",
    "\n",
    "    coverage = restore('coverage_dict.json') if exists('coverage_dict.json') else {}\n",
    "    spectacleMentions = restore('spectacleMentions_dict.json') if exists('spectacleMentions_dict.json') else {}\n",
    "   \n",
    "    requestCounter = 0\n",
    "\n",
    "    bro = reinitialise()\n",
    "    bro.get('https://www.newspapers.com/browse/united-kingdom/')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ################################################################### states ##############################################################################\n",
    "    stateElements = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[2]/div[2]/div/div/div/a')\n",
    "    stateLinks = [element.get_attribute('href') for element in stateElements]\n",
    "    stateNames = [element.text for element in stateElements]\n",
    "    for stateLink, stateName in tqdm(list(zip(stateLinks, stateNames))[::-1], position=0, desc='states done: ', leave=False):\n",
    "        \n",
    "        # get existing values if exists, otherwise put an empty dict\n",
    "        coverage[stateName] = coverage.get(stateName, {})\n",
    "        spectacleMentions[stateName] = spectacleMentions.get(stateName, {})\n",
    "\n",
    "        bro.get(stateLink)\n",
    "        wait(2, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ################################################################### cities ##############################################################################\n",
    "        cityElements = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[3]/div[2]/div/div/div/a')\n",
    "        cityLinks = [element.get_attribute('href') for element in cityElements]\n",
    "        cityNames = [element.text for element in cityElements]\n",
    "        for cityLink, cityName in tqdm(list(zip(cityLinks, cityNames)), position=1, desc='cities done: ', leave=False):\n",
    "            \n",
    "            # get existing values if exists, otherwise put an empty dict\n",
    "            coverage[stateName][cityName] = coverage[stateName].get(cityName, {})\n",
    "            spectacleMentions[stateName][cityName] = spectacleMentions[stateName].get(cityName, {})\n",
    "\n",
    "            bro.get(cityLink)\n",
    "            wait(2, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ################################################################### newspapers ##############################################################################\n",
    "            newspaperElements = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[4]/div[2]/div/div/div/a')\n",
    "            newspaperLinks = [element.get_attribute('href') for element in newspaperElements[::2]]  # the xpath hits both the newspaper title as well as the little info icon next to it -> every second list item is info\n",
    "            newspaperNames = [element.text for element in newspaperElements[::2]]\n",
    "            newspaperInfoLinks = [element.get_attribute('href') for element in newspaperElements[1::2]]\n",
    "            for newspaperLink, newspaperName, newspaperInfoLink in list(zip(newspaperLinks, newspaperNames, newspaperInfoLinks)):\n",
    "\n",
    "               \n",
    "\n",
    "                \n",
    "                # if the newspaper already has data (even if partial), skip to next newspaper\n",
    "                # otherwise, create an empty dict to fill later\n",
    "                # print(coverage[stateName][cityName].get(newspaperName))\n",
    "                if coverage[stateName][cityName].get(newspaperName) != None:\n",
    "                    continue\n",
    "                else:\n",
    "                    coverage[stateName][cityName][newspaperName] = {\n",
    "                        'data': {}, \n",
    "                        'location': {},\n",
    "                        }\n",
    "                    spectacleMentions[stateName][cityName][newspaperName] = {}\n",
    "\n",
    "\n",
    "\n",
    "                requestCounter += 1\n",
    "                if requestCounter % 400 == 0: \n",
    "                    bro = reinitialise()\n",
    "\n",
    "                bro.get(newspaperLink)\n",
    "                wait(2, 10)\n",
    "                resetView()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ################################################################### years ##############################################################################\n",
    "                yearElements = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[5]/div[2]/div/div/div/a')\n",
    "                yearLinks = [element.get_attribute('href') for element in yearElements]\n",
    "                yearNames = [element.text for element in yearElements]\n",
    "                for yearLink, yearName in tqdm(list(zip(yearLinks, yearNames)), position=2, desc='years done: ', leave=False):\n",
    "\n",
    "                    bro.get(yearLink)\n",
    "                    wait(2, 10)\n",
    "                    resetView()\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ################################################################### months ##############################################################################\n",
    "                    monthElements = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[6]/div[2]/div/div/div/a')\n",
    "                    monthLinks = [element.get_attribute('href') for element in monthElements]\n",
    "                    monthNames = [element.text for element in monthElements]\n",
    "                    for monthLink, monthName in list(zip(monthLinks, monthNames)):\n",
    "\n",
    "                    \n",
    "                        bro.get(monthLink)\n",
    "                        wait(2, 5)\n",
    "                        resetView()\n",
    "\n",
    "                        month = bro.current_url[-3:-1]\n",
    "                        date = f'{yearName}-{month}'\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "                        ######## get monthly number of publications ########\n",
    "                        publications = bro.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div/div[1]/div/div/div[7]/div[2]/div/div/div')\n",
    "                        coverage[stateName][cityName][newspaperName]['data'][date] = len(publications)\n",
    "\n",
    "\n",
    "                       \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        ######## get number of spectacle results ########\n",
    "                        # enter search terms\n",
    "                        keywordField = bro.find_element_by_id('searchText')\n",
    "                        keywordField.clear()\n",
    "                        keywordField.send_keys('spectacles OR glasses')\n",
    "                        keywordField.send_keys(Keys.ENTER)\n",
    "                        wait(2,5)\n",
    "                        \n",
    "                        # get results number\n",
    "                        try:\n",
    "                            resultsDescription = bro.find_element_by_xpath('//*[@id=\"SearchResults\"]/div[1]/p').text\n",
    "                            resultsString = resultsDescription.partition(' Matches')[0].replace(',', '')                # partitions at given string -> access first element\n",
    "\n",
    "                            if resultsString == 'No': \n",
    "                                numberOfResults = 0\n",
    "                            else:\n",
    "                                numberOfResults = int(resultsString)\n",
    "\n",
    "                                if numberOfResults > 180_000:\n",
    "                                    numberOfResults = np.nan\n",
    "\n",
    "                        except:\n",
    "                            numberOfResults = np.nan\n",
    "\n",
    "                        spectacleMentions[stateName][cityName][newspaperName][date] = numberOfResults\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        # restart client every 400 requests (two each time for initial page request, then search)\n",
    "                        requestCounter += 2\n",
    "                        if requestCounter > 400:\n",
    "                            requestCounter = 0 \n",
    "                            bro = reinitialise()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ######## get location ########\n",
    "                bro.get(newspaperInfoLink)\n",
    "\n",
    "                try: \n",
    "                    location = bro.find_element_by_xpath('//*[@id=\"titleheader\"]/div/div[1]/ul/li[1]').text\n",
    "                    coverage[stateName][cityName][newspaperName]['location'] = location\n",
    "                except:\n",
    "                    coverage[stateName][cityName][newspaperName]['location'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "                backup(coverage, path='coverage_dict.json')\n",
    "                backup(spectacleMentions, path='spectacleMentions_dict.json')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    unravelCoverage(coverage)\n",
    "    unravelSpectacleMentions(spectacleMentions)\n",
    "\n",
    "                \n",
    "\n",
    "scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage = restore('coverage_dict.json') if exists('coverage_dict.json') else {}\n",
    "# spectacleMentions = restore('spectacleMentions_dict.json') if exists('spectacleMentions_dict.json') else {}\n",
    "\n",
    "# unravelCoverage(coverage)\n",
    "# unravelSpectacleMentions(spectacleMentions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
